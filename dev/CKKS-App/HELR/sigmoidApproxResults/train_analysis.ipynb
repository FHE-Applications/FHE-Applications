{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54bc0082",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "\n",
    "- provide a plaintext interface to analyze step-by-step what is happening in the encrypted code\n",
    "\n",
    "- Used as a Python sanity check because I'm not that familiar with R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91303fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "from sklearn.metrics import log_loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e8a827",
   "metadata": {},
   "source": [
    "# Load and Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b06905b-9470-497d-8d70-e1082542e6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "\n",
    "def fwd(train_x, betas, dbg=False):\n",
    "    preds = train_x @ betas\n",
    "    if dbg:\n",
    "        print(f\"Logits: {preds}\")\n",
    "    return np.expand_dims(sigmoid(preds), -1)\n",
    "\n",
    "\n",
    "def calculate_gradient(train_x, train_y, betas, fwd, dbg):\n",
    "    preds = fwd(train_x, betas, dbg)\n",
    "    gradient = -train_x.T @ (train_y - preds) / len(train_y)\n",
    "    return gradient\n",
    "\n",
    "\n",
    "def cost(x, y, theta):\n",
    "    m = x.shape[0]\n",
    "    h = sigmoid(np.matmul(x, theta))\n",
    "\n",
    "    t1 = np.matmul(-y.T, np.log(h))\n",
    "\n",
    "    t2_a = (1 - y.T)\n",
    "    t2_b = np.log(np.clip(1 - h, 0.000000000000001, np.max(1 - h)))  # Used to get numerical issues\n",
    "    t2 = np.matmul(t2_a, t2_b)\n",
    "\n",
    "    return ((t1 - t2) / m)[0]\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Load data to compare against our reference Python (which was validated against R\n",
    "    \"\"\"\n",
    "\n",
    "    x_file = \"../train_data/X_norm_1024.csv\"\n",
    "    y_file = \"../train_data/y_1024.csv\"\n",
    "    train_x = pd.read_csv(x_file)\n",
    "    train_y = pd.read_csv(y_file)\n",
    "    train_y = train_y.to_numpy()\n",
    "    return train_x, train_y\n",
    "\n",
    "\n",
    "def nesterov(betas, epochs, lr, mu, train_x, train_y, breakout=True):\n",
    "    import copy\n",
    "\n",
    "    phi = copy.deepcopy(betas)\n",
    "    theta = copy.deepcopy(betas)\n",
    "\n",
    "    nesterov_loss = [0 for _ in range(epochs)]\n",
    "    # for i in tqdm.trange(epochs):\n",
    "    for i in range(epochs):\n",
    "        gradient = calculate_gradient(train_x, train_y, theta, fwd, dbg=False)\n",
    "\n",
    "        phi_prime = theta - lr * np.squeeze(gradient)\n",
    "\n",
    "        if i == 0:\n",
    "            theta = phi_prime\n",
    "        else:\n",
    "            theta = phi_prime + mu * (phi_prime - phi)\n",
    "\n",
    "        phi = phi_prime\n",
    "        loss = cost(train_x, train_y, theta)\n",
    "        nesterov_loss[i] = loss\n",
    "    return nesterov_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce32218",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, train_y = load_data()\n",
    "lr = 0.1\n",
    "mu = 0.1\n",
    "\n",
    "# Same shape as Marcelo's reference code\n",
    "betas = np.zeros((10, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e1e9d",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "1) We got the `loss_exact` and `loss_estimates` by modifying the relevant parts of Marcelo's code. Specifically the `cheb.gr` function in `chebyshev_approx.R`, \n",
    "\n",
    "```python\n",
    "p = cheb.sigmoid_approx(z, degree, range)\n",
    "# -- or --\n",
    "p = cheb.sigmoid(z)\n",
    "```\n",
    "\n",
    "where one gave us the exact NAG and the other was the approximate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf796c6-0a12-41d1-92bc-be405fba72cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    def __init__(self, name, degree):\n",
    "        self.name = name\n",
    "        self.degree = degree\n",
    "        self.data = None\n",
    "\n",
    "    def load_data(self):\n",
    "        with open(f\"raw_data/nag_{self.degree}_loss.csv\", \"r\") as f:\n",
    "            data = f.read()\n",
    "            train_losses = []\n",
    "            for i, ln in enumerate(data.split(\"\\n\")):\n",
    "                if i == 0 or i == len(data.split(\"\\n\")) - 1:\n",
    "                    continue\n",
    "                else:\n",
    "                    train_losses.append(float(ln.split(\",\")[1]))\n",
    "        self.data = np.asarray(train_losses)\n",
    "\n",
    "data_list = [\n",
    "    # Config(\"Degree16\", -16, 16, 32)\n",
    "    Config(\"Degree128\", 128),\n",
    "    Config(\"Degree119\", 119)\n",
    "]\n",
    "\n",
    "for el in data_list:\n",
    "    el.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac1bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = min([len(data.data) for data in data_list])\n",
    "\n",
    "loss_my_nesterov = nesterov(betas, num_epochs, lr, mu, train_x, train_y, breakout=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54d60d6",
   "metadata": {},
   "source": [
    "# Plots\n",
    "\n",
    "## Plot the exact losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088f8b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "xs = range(num_epochs)\n",
    "plt.plot(xs, loss_my_nesterov, color='r', label='Python Exact NAG Losses')\n",
    "for data in data_list:\n",
    "    \n",
    "    plt.plot(xs, data.data, label=f'Train losses for Approx(degree={data.degree}')\n",
    "    final_loss = data.data[-1]\n",
    "    plt.scatter(xs[-1], final_loss)\n",
    "    plt.annotate(f\"{final_loss: .8f}\", (xs[-1]-5, final_loss), annotation_clip=False)\n",
    "\n",
    "# Naming the x-axis, y-axis and the whole graph\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss against Epoch for Various Implementations\")\n",
    "plt.grid()\n",
    "# Adding legend, which helps us recognize the curve according to it's color\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"train_loss_plots/losses\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c0b5f7",
   "metadata": {},
   "source": [
    "## Plot the differences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1cb91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.figsize'] = [15, 10]\n",
    "\n",
    "\n",
    "xs = range(num_epochs)\n",
    "for data in data_list:\n",
    "    \n",
    "    plt.plot(xs, loss_my_nesterov - data.data, label=f'Python(NAG) - Approx(degree={data.degree})')\n",
    "    \n",
    "    final_loss = loss_my_nesterov[-1] - data.data[-1]\n",
    "    plt.scatter(xs[-1], final_loss)\n",
    "    plt.annotate(f\"{final_loss: .8f}\", (xs[-1]-5, final_loss-0.000025), annotation_clip=False)\n",
    "  \n",
    "# Naming the x-axis, y-axis and the whole graph\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.title(\"Epoch against Error\")\n",
    "plt.grid()\n",
    "# Adding legend, which helps us recognize the curve according to it's color\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(\"train_loss_plots/losses_diff\")\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4a95fe4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
