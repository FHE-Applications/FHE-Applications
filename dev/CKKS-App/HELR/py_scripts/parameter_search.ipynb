{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54bc0082",
   "metadata": {},
   "source": [
    "# Goal:\n",
    "\n",
    "- provide a plaintext interface to analyze step-by-step what is happening in the encrypted code\n",
    "\n",
    "- Used as a Python sanity check because I'm not that familiar with R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237ba67f-cd21-4d6b-9ff9-629b545daa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(42)\n",
    "\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f874f45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def sigmoid(z):\n",
    "    return 1/(1 + np.exp(-z))\n",
    "\n",
    "@njit\n",
    "def fwd(train_x, betas, dbg=False):\n",
    "    preds = train_x @ betas\n",
    "    return np.expand_dims(sigmoid(preds), -1)\n",
    "\n",
    "@njit\n",
    "def calculate_gradient(train_x, train_y, betas, fwd, dbg):\n",
    "    preds = fwd(train_x, betas, dbg)\n",
    "    gradient = -train_x.T @ (train_y - preds)  / len(train_y)\n",
    "    return gradient\n",
    "\n",
    "def cost(x, y, theta):\n",
    "    m = x.shape[0]\n",
    "    h = sigmoid(np.matmul(x, theta))\n",
    "    \n",
    "    t1 = np.matmul(-y.T, np.log(h))\n",
    "    \n",
    "    t2_a = (1 -y.T)\n",
    "    t2_b = np.log(np.clip(1-h, 0.000000000000001, np.max(1-h)))  # Used to get numerical issues\n",
    "    t2 = np.matmul(t2_a, t2_b)\n",
    "    \n",
    "    return ((t1 - t2) / m)[0]\n",
    "\n",
    "def nesterov(train_x, train_y, betas, epochs, lr, mu, breakout=True):\n",
    "    import copy\n",
    "\n",
    "    phi = copy.deepcopy(betas)\n",
    "    theta = copy.deepcopy(betas)\n",
    "    \n",
    "    #for i in tqdm.trange(epochs):\n",
    "    nesterov_loss = [0 for _ in range(epochs)]\n",
    "    prev_loss = None\n",
    "    for i in range(epochs):\n",
    "        gradient = calculate_gradient(train_x, train_y, theta, fwd, dbg=False)\n",
    "        \n",
    "        phi_prime = theta - lr * np.squeeze(gradient)\n",
    "\n",
    "        if i == 0:\n",
    "            theta = phi_prime\n",
    "        else:\n",
    "            theta = phi_prime + mu * (phi_prime - phi)\n",
    "\n",
    "        phi = phi_prime\n",
    "            \n",
    "        loss = cost(train_x, train_y, theta)\n",
    "        if not np.isfinite(loss):\n",
    "            print(\"Hit a non-numerical loss. Breaking out of current config\")\n",
    "            break\n",
    "        nesterov_loss[i] = loss\n",
    "        \n",
    "        if prev_loss and np.abs(loss - prev_loss) < 0.00005:\n",
    "            break\n",
    "        prev_loss = loss\n",
    "\n",
    "        #print(f\"New loss: {cost(train_x, train_y, v)[0]}\")\n",
    "    return nesterov_loss, loss, i, theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e8a827",
   "metadata": {},
   "source": [
    "# Load and Process the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce32218",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def load_data(shuffle=True):\n",
    "    X = pd.read_csv(\"../train_data/X_norm_32764.csv\").to_numpy()    \n",
    "    y = pd.read_csv(\"../train_data/y_32764.csv\").to_numpy()\n",
    "    idxs = np.random.permutation(len(X))\n",
    "    \n",
    "    if not shuffle:\n",
    "        return X, y\n",
    "    X = X[idxs]\n",
    "    y = y[idxs]\n",
    "    return X, y, len(X)\n",
    "\n",
    "X, y, num_samples = load_data()\n",
    "\n",
    "\n",
    "train_idx_end = round(0.85 * num_samples)\n",
    "train_x, train_y = X[:train_idx_end], y[:train_idx_end]\n",
    "test_x, test_y = X[train_idx_end:], y[train_idx_end:]\n",
    "\n",
    "# Same shape as Marcelo's reference code\n",
    "betas = np.zeros((10, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685998e3",
   "metadata": {},
   "source": [
    "# Nesterov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b1dffc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "lr = 0.1\n",
    "mu = 0.1\n",
    "\n",
    "r_script_nag_lr = 5.67349609\n",
    "r_script_nag_mu = 0.8738939\n",
    "\n",
    "ranges = [0.1, 0.2, 0.3]#, 0.4, 0.5, 0.75, r_script_nag_mu, 0.95, 1.2, 2.0, 3.0, r_script_nag_lr, 5.7]\n",
    "lr_range = ranges\n",
    "mu_range = ranges\n",
    "\n",
    "lr_track = []\n",
    "mu_track = []\n",
    "loss_seq_tracker = [] \n",
    "final_loss_track = []\n",
    "num_iters_track = []\n",
    "weights_tracker = [] \n",
    "test_roc_auc_tracker = [] \n",
    "train_roc_auc_tracker = [] \n",
    "tracker = {}\n",
    "\n",
    "for lr in tqdm.tqdm(lr_range):\n",
    "    for mu in mu_range:        \n",
    "        try:\n",
    "            losses, final_loss, num_iters, weights =  nesterov(train_x, train_y, betas, 1_000, lr, mu)\n",
    "            \n",
    "            \n",
    "            lr_track.append(lr)\n",
    "            mu_track.append(mu)\n",
    "            \n",
    "            weights_tracker.append(weights)\n",
    "            loss_seq_tracker.append(losses)\n",
    "            if np.isfinite(final_loss):    \n",
    "                num_iters_track.append(num_iters)\n",
    "                train_predictions = np.squeeze(fwd(train_x, weights))\n",
    "                train_roc_auc_tracker.append(roc_auc_score(np.squeeze(train_y), train_predictions))\n",
    "\n",
    "                test_predictions = np.squeeze(fwd(test_x, weights))\n",
    "                test_roc_auc_tracker.append(roc_auc_score(np.squeeze(test_y), test_predictions))\n",
    "                final_loss_track.append(final_loss)\n",
    "            else:\n",
    "                num_iters_track.append(-1)\n",
    "                train_roc_auc_tracker.append(0)\n",
    "                test_roc_auc_tracker.append(0)\n",
    "                final_loss_track.append(-1)\n",
    "            ############################################################\n",
    "            # Track the AUC/ROC\n",
    "            ############################################################\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            print(f\"Diverged on ({lr}, {mu})\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9145106f-3f07-43d3-85ac-31633aad02fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_val = {}\n",
    "val_to_idx = {}\n",
    "\n",
    "for i, el in enumerate(lr_range):\n",
    "    idx_to_val[i] = el\n",
    "    val_to_idx[el] = i\n",
    "    \n",
    "    \n",
    "\n",
    "x = [val_to_idx[v] for v in lr_track]\n",
    "y = [val_to_idx[v] for v in mu_track]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c95c0a-510a-4f67-92a1-8428d31b7222",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (15,12)\n",
    "\n",
    "def plot_convergence():\n",
    "    # create data\n",
    "    z = (1_000 - np.asarray(num_iters_track, dtype=np.float64))\n",
    "\n",
    "    fig=plt.figure(figsize=(15,10))\n",
    "    ax=fig.add_axes([0,0,1,1])\n",
    "\n",
    "\n",
    "    #ax.scatter(x, y, s=z, cmap=\"Blues\", alpha=0.25, edgecolors=\"grey\", linewidth=2, )\n",
    "    quantiles = np.quantile(\n",
    "            np.asarray(num_iters_track)[np.asarray(num_iters_track) > 0],\n",
    "            [0.05, 0.1, 0.25, 0.5]\n",
    "        )\n",
    "\n",
    "    print(quantiles)\n",
    "    \n",
    "    for (_lr, _mu, curr_iter, _z) in zip(x, y, num_iters_track, z):\n",
    "        if curr_iter == -1:\n",
    "            color = \"black\"\n",
    "            _z = 0\n",
    "        elif curr_iter < quantiles[0] and curr_iter != -1:\n",
    "            color = \"green\"\n",
    "            _z *= 3\n",
    "        elif quantiles[0] < curr_iter < quantiles[1]:\n",
    "            color = \"blue\"\n",
    "            _z *= 2\n",
    "        elif quantiles[1] < curr_iter < quantiles[2]:\n",
    "            color = \"yellow\" \n",
    "            z *= 1\n",
    "        else:\n",
    "            color=\"red\"\n",
    "            \n",
    "        ax.scatter(_lr, _mu, _z, c=color, alpha=0.3, )\n",
    "        ax.annotate(curr_iter, (_lr-0.1, _mu), fontsize=12.5, )\n",
    "\n",
    "    ax.set_xlabel(\"lr\")\n",
    "    ax.set_ylabel(\"mu\")\n",
    "    ax.set_title('learning rate and mu and their effect on convergence')\n",
    "\n",
    "    plt.xticks(range(len(ranges)), ranges)\n",
    "    plt.yticks(range(len(ranges)), ranges)\n",
    "\n",
    "    #plt.savefig(\"plots/lr_mu_convergence.jpg\", bbox_inches='tight', dpi=150)\n",
    "\n",
    "    # Show the graph\n",
    "    plt.show()\n",
    "plot_convergence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89347f-264b-4ad8-9df2-d15617e16d3a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (15,12)\n",
    "\n",
    "def plot_loss():\n",
    "    z = (np.asarray(final_loss_track, dtype=np.float64))\n",
    "    masked_z = z[z >=0]\n",
    "    z = (z / min(masked_z)) ** -1 * 1000\n",
    "\n",
    "    fig=plt.figure(figsize=(15,10))\n",
    "    ax=fig.add_axes([0,0,1,1])\n",
    "\n",
    "\n",
    "    #ax.scatter(x, y, s=z, cmap=\"Blues\", alpha=0.25, edgecolors=\"grey\", linewidth=2, )\n",
    "    quantiles = np.quantile(\n",
    "            np.asarray(final_loss_track)[np.asarray(final_loss_track) > 0],\n",
    "            [0.05, 0.1, 0.25, 0.5]\n",
    "        )\n",
    "\n",
    "    print(quantiles)\n",
    "    colors= [] \n",
    "    \n",
    "    for (_lr, _mu, curr_loss, _z) in zip(x, y, final_loss_track, z):\n",
    "        if curr_loss == -1:\n",
    "            color=\"black\"\n",
    "        if curr_loss < quantiles[0]:\n",
    "            color = \"green\"\n",
    "            _z += 500\n",
    "        elif quantiles[0] < curr_loss < quantiles[1]:\n",
    "            color = \"blue\"\n",
    "            _z += 250\n",
    "        elif quantiles[1] < curr_loss < quantiles[2]:\n",
    "            color = \"yellow\"\n",
    "            _z += 50\n",
    "        else:\n",
    "            color=\"r\"\n",
    "        colors.append(color)\n",
    "\n",
    "        ax.annotate(f\"{curr_loss:.5f}\", (_lr-0.1, _mu-0.2), fontsize=12.5)\n",
    "    ax.scatter(x, y, z, c=colors, alpha=0.25)\n",
    "    # ax.scatter(x, y, s=z, cmap=\"Blues\", alpha=0.25, edgecolors=\"grey\", linewidth=2, )\n",
    "\n",
    "    # for (_lr, _mu, curr_loss) in zip(x, y, final_loss_track):\n",
    "    #     ax.annotate(f\"{curr_loss:.5f}\", (_lr-0.05, _mu-0.2), fontsize=12.5)\n",
    "\n",
    "\n",
    "    ax.set_xlabel(\"lr\")\n",
    "    ax.set_ylabel(\"mu\")\n",
    "    ax.set_title('learning rate and mu and their effect on final loss')\n",
    "\n",
    "    plt.xticks(range(len(ranges)), ranges)\n",
    "    plt.yticks(range(len(ranges)), ranges)\n",
    "\n",
    "    #plt.savefig(\"plots/final_loss.jpg\", bbox_inches='tight', dpi=150)\n",
    "\n",
    "    # Show the graph\n",
    "    plt.show()\n",
    "plot_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d70fc3-8fab-4d92-8c7c-db46e739f273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "plt.rcParams[\"figure.figsize\"] = (15,12)\n",
    "\n",
    "def plot_aucroc(aucroc_scores, name):\n",
    "    z = (np.asarray(aucroc_scores, dtype=np.float64)) * 1000\n",
    "\n",
    "    fig=plt.figure(figsize=(15,10))\n",
    "    ax=fig.add_axes([0,0,1,1])\n",
    "\n",
    "    #ax.scatter(x, y, s=z, cmap=\"Blues\", alpha=0.25, edgecolors=\"grey\", linewidth=2, )\n",
    "    quantiles = np.quantile(\n",
    "            np.asarray(aucroc_scores)[np.asarray(aucroc_scores) > 0],\n",
    "            [0.95, 0.9, 0.75, 0.5]\n",
    "        )\n",
    "\n",
    "    print(quantiles)\n",
    "    \n",
    "    colors = []\n",
    "    for (_lr, _mu, aucroc, _z) in zip(x, y, aucroc_scores, z):\n",
    "        if aucroc >= quantiles[0]:\n",
    "            color = \"green\"\n",
    "        elif quantiles[1] <= aucroc <quantiles[0] :\n",
    "            color = \"yellow\"\n",
    "        elif quantiles[2] < aucroc < quantiles[1]:\n",
    "            color = \"blue\"\n",
    "        else:\n",
    "            color=\"red\"\n",
    "        colors.append(color)\n",
    "        ax.annotate(f\"{aucroc:.4f}\", (_lr, _mu), fontsize=12.5, )\n",
    "            \n",
    "    ax.scatter(x, y, z, c=colors, alpha=0.5)\n",
    "        \n",
    "\n",
    "\n",
    "    ax.set_xlabel(\"lr\")\n",
    "    ax.set_ylabel(\"mu\")\n",
    "    ax.set_title(f'learning rate and mu and their effect on {name} AUC-ROC')\n",
    "\n",
    "    plt.xticks(range(len(ranges)), ranges)\n",
    "    plt.yticks(range(len(ranges)), ranges)\n",
    "\n",
    "    #plt.savefig(f\"plots/{name}_aucroc.jpg\", bbox_inches='tight', dpi=150)\n",
    "\n",
    "    # Show the graph\n",
    "    plt.show()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14980aa-734f-4563-bd99-c8b1b46d0a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_aucroc(train_roc_auc_tracker, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a04dd6-9b08-4266-a839-e584e6df6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_aucroc(test_roc_auc_tracker, \"test\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
